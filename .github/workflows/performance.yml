name: Performance Testing

on:
  push:
    branches: [main]
    paths:
      - 'src/**'
      - 'examples/**'
  pull_request:
    branches: [main]
    paths:
      - 'src/**'
      - 'examples/**'
  schedule:
    # Run performance tests weekly on Sundays at 3 AM UTC
    - cron: '0 3 * * 0'
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  benchmark:
    name: Benchmark Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-bun

      - name: Run benchmarks
        run: |
          # Create a simple benchmark script if it doesn't exist
          if [ ! -f "benchmark.ts" ]; then
            cat > benchmark.ts << 'EOF'
            import { performance } from 'perf_hooks';
            import { StatsClient } from './src/index';

            async function benchmark() {
              console.log('🏃 Running performance benchmarks...');
              
              // Database initialization benchmark
              const start = performance.now();
              const client = new StatsClient({
                database: { path: ':memory:' },
                cache: { enabled: false }
              });
              const initTime = performance.now() - start;
              
              console.log(`Database initialization: ${initTime.toFixed(2)}ms`);
              
              // Basic operations benchmark
              const opStart = performance.now();
              for (let i = 0; i < 100; i++) {
                await client.getUserStats('test-guild', 'test-user', 30);
              }
              const opTime = performance.now() - opStart;
              
              console.log(`100 getUserStats operations: ${opTime.toFixed(2)}ms`);
              console.log(`Average per operation: ${(opTime / 100).toFixed(2)}ms`);
              
              await client.close();
            }

            benchmark().catch(console.error);
            EOF
          fi
          
          bun run benchmark.ts

      - name: Memory usage test
        run: |
          # Create memory test script
          cat > memory-test.ts << 'EOF'
          import { StatsClient } from './src/index';

          async function memoryTest() {
            console.log('🧠 Testing memory usage...');
            
            const initialMemory = process.memoryUsage();
            console.log('Initial memory:', initialMemory);
            
            // Create multiple clients to test memory usage
            const clients = [];
            for (let i = 0; i < 10; i++) {
              const client = new StatsClient({
                database: { path: ':memory:' },
                cache: { enabled: true, ttl: 300 }
              });
              clients.push(client);
            }
            
            const afterCreation = process.memoryUsage();
            console.log('After creating 10 clients:', afterCreation);
            
            // Perform operations
            for (const client of clients) {
              for (let i = 0; i < 50; i++) {
                await client.getUserStats('guild-' + i, 'user-' + i, 30);
              }
            }
            
            const afterOperations = process.memoryUsage();
            console.log('After operations:', afterOperations);
            
            // Cleanup
            for (const client of clients) {
              await client.close();
            }
            
            const afterCleanup = process.memoryUsage();
            console.log('After cleanup:', afterCleanup);
            
            // Calculate memory increase
            const memoryIncrease = afterOperations.heapUsed - initialMemory.heapUsed;
            console.log(`Memory increase: ${(memoryIncrease / 1024 / 1024).toFixed(2)} MB`);
            
            if (memoryIncrease > 100 * 1024 * 1024) { // 100MB threshold
              console.warn('⚠️ High memory usage detected');
              process.exit(1);
            }
          }

          memoryTest().catch(console.error);
          EOF
          
          bun run memory-test.ts

  load-test:
    name: Load Testing
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-bun

      - name: Install load testing tools
        run: bun add -g autocannon

      - name: Create test server
        run: |
          # Create a simple HTTP server for load testing
          cat > test-server.ts << 'EOF'
          import { StatsClient } from './src/index';

          const client = new StatsClient({
            database: { path: ':memory:' },
            cache: { enabled: true, ttl: 300 }
          });

          const server = Bun.serve({
            port: 3000,
            async fetch(req) {
              const url = new URL(req.url);
              
              if (url.pathname === '/stats') {
                const guildId = url.searchParams.get('guild') || 'test-guild';
                const userId = url.searchParams.get('user') || 'test-user';
                const days = parseInt(url.searchParams.get('days') || '30');
                
                try {
                  const stats = await client.getUserStats(guildId, userId, days);
                  return Response.json(stats);
                } catch (error) {
                  return Response.json({ error: 'Failed to get stats' }, { status: 500 });
                }
              }
              
              return new Response('Not found', { status: 404 });
            },
          });

          console.log(`Server running on http://localhost:${server.port}`);
          
          // Keep server running
          process.on('SIGTERM', async () => {
            await client.close();
            server.stop();
          });
          EOF

      - name: Start test server
        run: |
          bun run test-server.ts &
          SERVER_PID=$!
          echo "SERVER_PID=$SERVER_PID" >> $GITHUB_ENV
          
          # Wait for server to start
          sleep 5

      - name: Run load test
        run: |
          # Run load test with autocannon
          autocannon -c 10 -d 30 -p 10 http://localhost:3000/stats?guild=test&user=test&days=30
          
          # Test with different parameters
          autocannon -c 5 -d 15 -p 5 http://localhost:3000/stats?guild=load-test&user=user-1&days=7

      - name: Stop test server
        if: always()
        run: |
          if [ ! -z "$SERVER_PID" ]; then
            kill $SERVER_PID || true
          fi

  bundle-size:
    name: Bundle Size Analysis
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - uses: ./.github/actions/setup-bun

      - name: Build and analyze bundle
        run: |
          bun run build
          
          # Get bundle size
          if [ -d "dist" ]; then
            bundle_size=$(du -sh dist/ | cut -f1)
            echo "Bundle size: $bundle_size"
            
            # Detailed analysis
            echo "## Bundle Analysis" >> bundle-analysis.md
            echo "- Total size: $bundle_size" >> bundle-analysis.md
            echo "" >> bundle-analysis.md
            echo "### File breakdown:" >> bundle-analysis.md
            find dist/ -type f -name "*.js" -o -name "*.ts" -o -name "*.d.ts" | while read file; do
              size=$(du -h "$file" | cut -f1)
              echo "- $file: $size" >> bundle-analysis.md
            done
          fi

      - name: Compare with base branch
        if: github.event_name == 'pull_request'
        run: |
          # Checkout base branch and build
          git checkout origin/${{ github.base_ref }}
          bun install
          bun run build
          base_size=$(du -s dist/ | cut -f1)
          
          # Checkout PR branch and build
          git checkout ${{ github.sha }}
          bun install
          bun run build
          pr_size=$(du -s dist/ | cut -f1)
          
          # Calculate difference
          size_diff=$((pr_size - base_size))
          
          echo "## Bundle Size Comparison" >> $GITHUB_STEP_SUMMARY
          echo "- Base: ${base_size}KB" >> $GITHUB_STEP_SUMMARY
          echo "- PR: ${pr_size}KB" >> $GITHUB_STEP_SUMMARY
          echo "- Difference: ${size_diff}KB" >> $GITHUB_STEP_SUMMARY
          
          if [ $size_diff -gt 100 ]; then
            echo "⚠️ Bundle size increased significantly (+${size_diff}KB)" >> $GITHUB_STEP_SUMMARY
          elif [ $size_diff -lt -100 ]; then
            echo "✅ Bundle size decreased by ${size_diff#-}KB" >> $GITHUB_STEP_SUMMARY
          else
            echo "✅ Bundle size change is minimal" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload bundle analysis
        uses: actions/upload-artifact@v4
        with:
          name: bundle-analysis
          path: bundle-analysis.md
          retention-days: 30

  performance-summary:
    name: Performance Summary
    runs-on: ubuntu-latest
    needs: [benchmark, load-test, bundle-size]
    if: always()
    steps:
      - name: Performance Summary
        run: |
          echo "## ⚡ Performance Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.benchmark.result }}" = "success" ]; then
            echo "✅ **Benchmark Tests**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Benchmark Tests**: Failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.load-test.result }}" = "success" ]; then
            echo "✅ **Load Testing**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Load Testing**: Failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.bundle-size.result }}" = "success" ]; then
            echo "✅ **Bundle Analysis**: Completed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Bundle Analysis**: Failed" >> $GITHUB_STEP_SUMMARY
          fi
